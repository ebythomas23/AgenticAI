{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccb2b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150d79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ff67ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ebythomas/agentic_ai_2.0/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e54c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0804559513926506,\n",
       " 0.034740377217531204,\n",
       " 0.04197044298052788,\n",
       " 0.03294932469725609,\n",
       " -0.010872798971831799,\n",
       " -0.12379563599824905,\n",
       " 0.07415368407964706,\n",
       " -0.004162954166531563,\n",
       " 0.024259595200419426,\n",
       " -0.03343378007411957,\n",
       " 0.023308560252189636,\n",
       " 0.009776068851351738,\n",
       " -0.025727197527885437,\n",
       " -0.03764554113149643,\n",
       " 0.021908365190029144,\n",
       " -0.026956304907798767,\n",
       " -0.0011933626374229789,\n",
       " 0.03142086789011955,\n",
       " -0.12250586599111557,\n",
       " 0.009405857883393764,\n",
       " -0.02580174058675766,\n",
       " 0.0786590650677681,\n",
       " 0.024827489629387856,\n",
       " 0.020943712443113327,\n",
       " -0.0402349978685379,\n",
       " -0.04566637799143791,\n",
       " 0.050649214535951614,\n",
       " 0.06266313791275024,\n",
       " -0.02059992030262947,\n",
       " 0.01860896311700344,\n",
       " 0.10433365404605865,\n",
       " -0.021139739081263542,\n",
       " 0.05518506094813347,\n",
       " -0.0034993323497474194,\n",
       " -0.011035328730940819,\n",
       " 0.06912391632795334,\n",
       " 0.024093015119433403,\n",
       " -0.02313392609357834,\n",
       " 0.01079131942242384,\n",
       " 0.02780058979988098,\n",
       " -0.02478250488638878,\n",
       " -0.0117954658344388,\n",
       " -0.017575176432728767,\n",
       " 0.0311643797904253,\n",
       " 0.020911874249577522,\n",
       " 0.034649066627025604,\n",
       " 0.01684698648750782,\n",
       " 0.03557023033499718,\n",
       " 0.013146265409886837,\n",
       " 0.01785729080438614,\n",
       " -0.08532533049583435,\n",
       " -0.10858983546495438,\n",
       " -0.007912672124803066,\n",
       " 0.0352834090590477,\n",
       " 0.05369578301906586,\n",
       " 0.022338807582855225,\n",
       " 0.030054578557610512,\n",
       " -0.025283008813858032,\n",
       " 0.07825623452663422,\n",
       " -0.057691168040037155,\n",
       " -0.010927991010248661,\n",
       " 0.017406031489372253,\n",
       " -0.00040338438702747226,\n",
       " -0.01431729830801487,\n",
       " 0.037622109055519104,\n",
       " -0.05481276288628578,\n",
       " -0.08155445009469986,\n",
       " -0.012936416082084179,\n",
       " -0.03828331083059311,\n",
       " -0.04179492965340614,\n",
       " -0.018367517739534378,\n",
       " 0.010145879350602627,\n",
       " -0.060719314962625504,\n",
       " 0.02312062680721283,\n",
       " -0.013108192011713982,\n",
       " -0.03024141676723957,\n",
       " 0.027776317670941353,\n",
       " -0.0844750925898552,\n",
       " 0.09208283573389053,\n",
       " 0.010675420984625816,\n",
       " 0.05907291918992996,\n",
       " -0.06859065592288971,\n",
       " -0.01690211147069931,\n",
       " 0.031278714537620544,\n",
       " 0.05583832412958145,\n",
       " -0.07077447324991226,\n",
       " -0.02978462539613247,\n",
       " 0.025203408673405647,\n",
       " -0.003982230089604855,\n",
       " 0.021856172010302544,\n",
       " -0.12000562995672226,\n",
       " 0.0574769601225853,\n",
       " -0.036625005304813385,\n",
       " -0.015142258256673813,\n",
       " -0.05672639235854149,\n",
       " -0.05587045103311539,\n",
       " 0.044266119599342346,\n",
       " 0.02635476179420948,\n",
       " -0.15519802272319794,\n",
       " 0.18577595055103302,\n",
       " -0.015671513974666595,\n",
       " 0.06884128600358963,\n",
       " 0.016124282032251358,\n",
       " 0.07655911892652512,\n",
       " -0.057335857301950455,\n",
       " -0.06042471155524254,\n",
       " -0.02899685502052307,\n",
       " 0.09683789312839508,\n",
       " -0.039512522518634796,\n",
       " -0.07719079405069351,\n",
       " 0.008421441540122032,\n",
       " -0.05394061282277107,\n",
       " 0.004851602483540773,\n",
       " 0.03602161258459091,\n",
       " 0.07461558282375336,\n",
       " 0.019862137734889984,\n",
       " -0.020445270463824272,\n",
       " 0.0886409729719162,\n",
       " -0.012449423782527447,\n",
       " -0.05415346100926399,\n",
       " 0.02855290286242962,\n",
       " -0.04771926626563072,\n",
       " 0.027452116832137108,\n",
       " 0.0007404488860629499,\n",
       " -0.0308696161955595,\n",
       " -0.010027422569692135,\n",
       " 0.0502779558300972,\n",
       " 3.2026072673439557e-34,\n",
       " 0.1358385980129242,\n",
       " -0.0666961818933487,\n",
       " -0.04676744341850281,\n",
       " 0.13523444533348083,\n",
       " -0.050429828464984894,\n",
       " -0.008889451622962952,\n",
       " -0.06450152397155762,\n",
       " -0.04233105853199959,\n",
       " 0.02728353440761566,\n",
       " -0.0641784742474556,\n",
       " 0.08396089822053909,\n",
       " -0.07041534036397934,\n",
       " -0.0627949982881546,\n",
       " 0.03745749220252037,\n",
       " 0.006795013323426247,\n",
       " 0.024886371567845345,\n",
       " -0.046158257871866226,\n",
       " 0.0417315736413002,\n",
       " -0.002388184890151024,\n",
       " 0.03405744954943657,\n",
       " -0.05860064551234245,\n",
       " -0.0010367576032876968,\n",
       " 0.05373670905828476,\n",
       " 0.07251642644405365,\n",
       " 0.07097700983285904,\n",
       " -0.02033776231110096,\n",
       " -0.03214515000581741,\n",
       " -0.04438014701008797,\n",
       " 0.11003473401069641,\n",
       " 0.040740225464105606,\n",
       " 0.06382295489311218,\n",
       " -0.06172221153974533,\n",
       " 0.028426628559827805,\n",
       " 0.028984183445572853,\n",
       " 0.02161671407520771,\n",
       " 0.05372980237007141,\n",
       " -0.03315238282084465,\n",
       " -0.05558029189705849,\n",
       " -0.06295845657587051,\n",
       " -0.07373237609863281,\n",
       " -0.043928973376750946,\n",
       " 0.02401578053832054,\n",
       " 0.032649096101522446,\n",
       " -0.03772764280438423,\n",
       " 0.06416505575180054,\n",
       " 0.021406235173344612,\n",
       " -0.04325920343399048,\n",
       " 0.04693849757313728,\n",
       " 0.011580300517380238,\n",
       " 0.03225431218743324,\n",
       " -0.08200536668300629,\n",
       " 0.06683874130249023,\n",
       " -0.06339385360479355,\n",
       " 0.028445200994610786,\n",
       " -0.010047674179077148,\n",
       " -0.10390295088291168,\n",
       " -0.013797430321574211,\n",
       " -0.013757966458797455,\n",
       " 0.026815835386514664,\n",
       " 0.007875568233430386,\n",
       " -0.044750846922397614,\n",
       " 0.1275269240140915,\n",
       " 0.008272350765764713,\n",
       " 0.08698105067014694,\n",
       " -0.06689499318599701,\n",
       " -0.05562003329396248,\n",
       " 0.0705152153968811,\n",
       " -0.054710716009140015,\n",
       " 0.01428142935037613,\n",
       " 0.009620406664907932,\n",
       " 0.010928146541118622,\n",
       " -0.0032297398429363966,\n",
       " 0.0037114296574145555,\n",
       " 0.03601818531751633,\n",
       " -0.00788326095789671,\n",
       " -0.0026708682999014854,\n",
       " 0.10067711770534515,\n",
       " -0.053053878247737885,\n",
       " -0.014331919141113758,\n",
       " -0.06047288700938225,\n",
       " 0.0073932562954723835,\n",
       " 0.009593511931598186,\n",
       " -0.06891260296106339,\n",
       " -0.04094581678509712,\n",
       " 0.05003341659903526,\n",
       " -0.022338107228279114,\n",
       " -0.06817600876092911,\n",
       " -0.14042197167873383,\n",
       " -0.027607956901192665,\n",
       " -0.02085895836353302,\n",
       " -0.06683538854122162,\n",
       " 0.03860974311828613,\n",
       " 0.043621186167001724,\n",
       " -0.015932021662592888,\n",
       " -0.003820021403953433,\n",
       " -4.375211555102151e-34,\n",
       " 0.054792385548353195,\n",
       " 0.07162177562713623,\n",
       " -0.049716588109731674,\n",
       " -0.0367552675306797,\n",
       " -0.1091143935918808,\n",
       " -0.004720509983599186,\n",
       " -0.07442211359739304,\n",
       " 0.10757578909397125,\n",
       " -0.060134101659059525,\n",
       " -0.04023660719394684,\n",
       " 0.07261883467435837,\n",
       " -0.05826188996434212,\n",
       " -0.01918654330074787,\n",
       " 0.06995563209056854,\n",
       " 0.0854380875825882,\n",
       " -0.012757047079503536,\n",
       " 0.13636058568954468,\n",
       " -0.020942440256476402,\n",
       " -0.008435861207544804,\n",
       " 0.018699701875448227,\n",
       " 0.008012398146092892,\n",
       " 0.02484244480729103,\n",
       " -0.060236454010009766,\n",
       " -0.0033188939560204744,\n",
       " 0.0608745813369751,\n",
       " 0.048708949238061905,\n",
       " 0.01183057576417923,\n",
       " 0.028085848316550255,\n",
       " -0.12069231271743774,\n",
       " -0.026805203408002853,\n",
       " 0.05445587635040283,\n",
       " 0.03190961852669716,\n",
       " -0.019859198480844498,\n",
       " 0.05402863398194313,\n",
       " -0.07107710838317871,\n",
       " 0.08867332339286804,\n",
       " 0.04278687387704849,\n",
       " -0.05895334482192993,\n",
       " 0.005590228363871574,\n",
       " -0.02493325062096119,\n",
       " -0.00834889616817236,\n",
       " -0.006740061100572348,\n",
       " -0.03681986778974533,\n",
       " 0.03441523760557175,\n",
       " -0.08874780684709549,\n",
       " -0.040856167674064636,\n",
       " -0.050776537507772446,\n",
       " 0.022017326205968857,\n",
       " 0.028723230585455894,\n",
       " -0.008557969704270363,\n",
       " -0.018471524119377136,\n",
       " 0.02897542528808117,\n",
       " 0.01885848678648472,\n",
       " -0.04375078156590462,\n",
       " 0.061204854398965836,\n",
       " -0.01204933226108551,\n",
       " 0.02030758559703827,\n",
       " 0.01799906976521015,\n",
       " -0.05734967067837715,\n",
       " -0.05007024481892586,\n",
       " 0.008448203094303608,\n",
       " 0.0513971671462059,\n",
       " 0.012813339941203594,\n",
       " 0.06733180582523346,\n",
       " -0.022724315524101257,\n",
       " 0.009043876081705093,\n",
       " -0.034915730357170105,\n",
       " 0.039920028299093246,\n",
       " 0.014722148887813091,\n",
       " -0.02800442837178707,\n",
       " 0.009079515002667904,\n",
       " 0.011682739481329918,\n",
       " 0.029090026393532753,\n",
       " 0.00035981147084385157,\n",
       " 0.002907948102802038,\n",
       " -0.026870742440223694,\n",
       " 0.0100916288793087,\n",
       " 0.06344141811132431,\n",
       " 0.02948131039738655,\n",
       " 0.09080009907484055,\n",
       " 0.009040003642439842,\n",
       " 0.02387849986553192,\n",
       " 0.019518084824085236,\n",
       " 0.008011375553905964,\n",
       " 0.014742173254489899,\n",
       " -0.04743288829922676,\n",
       " 0.02857154794037342,\n",
       " 0.08037816733121872,\n",
       " 0.06360115110874176,\n",
       " -0.0016782728489488363,\n",
       " -0.002536801155656576,\n",
       " 0.018987488001585007,\n",
       " 0.07649585604667664,\n",
       " -0.0021019207779318094,\n",
       " 0.008756264112889767,\n",
       " -1.8416026037471056e-08,\n",
       " -0.032766152173280716,\n",
       " -0.07498135417699814,\n",
       " 0.0377434603869915,\n",
       " -0.006661274470388889,\n",
       " 0.0179115179926157,\n",
       " 0.03736060485243797,\n",
       " -0.007916981354355812,\n",
       " -0.03168824315071106,\n",
       " -0.05370086058974266,\n",
       " 0.04613761231303215,\n",
       " 0.02965690754354,\n",
       " 0.13228778541088104,\n",
       " -0.055572763085365295,\n",
       " -0.077205590903759,\n",
       " 0.0927286371588707,\n",
       " -0.00028700826806016266,\n",
       " -0.07105865329504013,\n",
       " 0.004180466756224632,\n",
       " -0.0851789340376854,\n",
       " -0.07886505872011185,\n",
       " 0.044523075222969055,\n",
       " 0.0021643242798745632,\n",
       " -0.011038163676857948,\n",
       " -0.0008439093362540007,\n",
       " -0.012406552210450172,\n",
       " -0.047572363168001175,\n",
       " -0.02269350364804268,\n",
       " -0.054492026567459106,\n",
       " -0.06135684251785278,\n",
       " -0.0012543769553303719,\n",
       " 0.010946073569357395,\n",
       " 0.1292513906955719,\n",
       " -0.01434711366891861,\n",
       " -0.016704924404621124,\n",
       " -0.014327216893434525,\n",
       " 0.00016943075752351433,\n",
       " -0.022951042279601097,\n",
       " 0.01777467504143715,\n",
       " -0.0018457532860338688,\n",
       " 0.02444060519337654,\n",
       " -0.07163137197494507,\n",
       " 0.03265758603811264,\n",
       " -0.017663734033703804,\n",
       " -0.02360490709543228,\n",
       " -0.015536271966993809,\n",
       " 0.011170200072228909,\n",
       " -0.005081497132778168,\n",
       " -0.05196048691868782,\n",
       " -0.0226640235632658,\n",
       " -0.04191572964191437,\n",
       " -0.052277594804763794,\n",
       " 0.004741923417896032,\n",
       " 0.14102859795093536,\n",
       " 0.042367298156023026,\n",
       " -0.010610345751047134,\n",
       " 0.0775962844491005,\n",
       " 0.04271925613284111,\n",
       " -0.01662624441087246,\n",
       " -0.07299685478210449,\n",
       " 0.008720631711184978,\n",
       " 0.023350566625595093,\n",
       " 0.025074200704693794,\n",
       " 0.011280053295195103,\n",
       " -0.011797863058745861]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.embed_query(\"hello wolrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7fc54ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8b2742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abdedb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19f0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297b3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key =os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4ca7ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pcsk_6AdRZA_D8TT1prsR4iPazhAe6PgeNgDpBf5MQzPuaaDmnVUBUMpMGKAdAqKz5TWUBvhE7i'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ce2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d58315f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "# serverless : server will be managed by the cloud provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0719ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"agenticai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82db13f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.has_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9fc18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a index\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c67fd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e1acc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da636ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(index=index,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93baf515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results= vector_store.similarity_search(\"what is langchain\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f9e2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdcfa87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cc3019f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
       " Document(metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
       " Document(metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
       " Document(metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :(')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e60554b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95ef5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7f8dd69f-de8d-48b7-a59c-6e66ccac93c4\n",
      "1\n",
      "69f5d394-81e4-4269-ad8d-8fe8453ca1a3\n",
      "2\n",
      "4d8472da-d44e-4afb-aa40-ef2c7fbf4337\n",
      "3\n",
      "a6ee7774-57be-4cfb-9744-2c6b01c3ec23\n",
      "4\n",
      "2bba003b-e0c4-407c-b08b-fc2814020f13\n",
      "5\n",
      "c8fe1c27-2d79-486c-a84c-b2439ab6f2db\n",
      "6\n",
      "d1a45645-6a68-40fa-b795-ff07919d3b65\n",
      "7\n",
      "b2cfda75-fbde-4e36-ae3a-2a0776fe1359\n",
      "8\n",
      "eebe30bb-0f4f-4f82-ad23-7af77b47a9d1\n",
      "9\n",
      "f276302f-7cac-46d2-a528-7963b6ed1194\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "for _ in range(len(documents)):\n",
    "    print(_)\n",
    "    print(str(uuid4()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03504365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8400a594-b722-45b4-ba6c-057a54cab263',\n",
       " '17450d64-cbed-4ab6-b3db-7afdf59b0bef',\n",
       " '18af67a0-728a-4c6f-97cf-a5fafe09fea4',\n",
       " '1c3ecaee-7373-4c5d-950e-e1b86a6cedf5',\n",
       " '867a0259-568e-4d78-80e9-20fdfe73508f',\n",
       " '99dc7593-2f37-4073-b4bb-02aa24e675bb',\n",
       " '476f034b-1829-4ad0-b780-bc5e74846c3e',\n",
       " '21701cf9-1dd4-4142-bc3a-599d5e49d098',\n",
       " '47d02d5a-2c5e-4675-af5f-8d2144fc8df1',\n",
       " '60838da4-a047-41e7-94c1-7594e4b763a0']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuids =[str(uuid4()) for _ in range(len(documents))]\n",
    "uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d51dceb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8400a594-b722-45b4-ba6c-057a54cab263',\n",
       " '17450d64-cbed-4ab6-b3db-7afdf59b0bef',\n",
       " '18af67a0-728a-4c6f-97cf-a5fafe09fea4',\n",
       " '1c3ecaee-7373-4c5d-950e-e1b86a6cedf5',\n",
       " '867a0259-568e-4d78-80e9-20fdfe73508f',\n",
       " '99dc7593-2f37-4073-b4bb-02aa24e675bb',\n",
       " '476f034b-1829-4ad0-b780-bc5e74846c3e',\n",
       " '21701cf9-1dd4-4142-bc3a-599d5e49d098',\n",
       " '47d02d5a-2c5e-4675-af5f-8d2144fc8df1',\n",
       " '60838da4-a047-41e7-94c1-7594e4b763a0']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=documents,ids=uuids )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc7af199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='18af67a0-728a-4c6f-97cf-a5fafe09fea4', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"what langchain provides to us?\",k=1)\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dae2a86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='18af67a0-728a-4c6f-97cf-a5fafe09fea4', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='21701cf9-1dd4-4142-bc3a-599d5e49d098', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(id='60838da4-a047-41e7-94c1-7594e4b763a0', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :('),\n",
       " Document(id='867a0259-568e-4d78-80e9-20fdfe73508f', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\")]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"what langchain provides to us?\",filter={\"source\": \"tweet\"})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29d5843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver =vector_store.as_retriever(\n",
    "    search_type =\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\":0.7}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b273d40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='18af67a0-728a-4c6f-97cf-a5fafe09fea4', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='21701cf9-1dd4-4142-bc3a-599d5e49d098', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(id='60838da4-a047-41e7-94c1-7594e4b763a0', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :('),\n",
       " Document(id='867a0259-568e-4d78-80e9-20fdfe73508f', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\")]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreiver.invoke(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71b15a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model =ChatGoogleGenerativeAI(model='gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76b49860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt =hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa132193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d91551",
   "metadata": {},
   "source": [
    "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b6c52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f9119cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\",\n",
    "    input_variables = ['context','question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c71aa925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7a11999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: what is lanchain \\nContext: langchain is very super framework for llm. \\nAnswer:\")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\":\"what is lanchain\",\"context\":\"langchain is very super framework for llm.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38120fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c69de18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02823ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\":retreiver|format_docs, \"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a408214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.  The provided text does not contain information about Llama models.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is llama model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45f5a518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided text, LangChain is a framework used for building projects.  The context snippet suggests it's used in creating something exciting.  More information is needed for a complete definition.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ec6f8",
   "metadata": {},
   "source": [
    "# : take a multiple pdf with text,image,table\n",
    "1. fetch the data from pdf\n",
    "2. at lesat there should be 200 pages\n",
    "3. if chunking(use the sementic chunking technique) required do chunking and then embedding\n",
    "4. store it inside the vector database(use any of them 1. mongodb 2. astradb 3. opensearch 4.milvus) ## i have not discuss then you need to explore\n",
    "5. create a index with all three index machnism(Flat, HNSW, IVF) ## i have not discuss then you need to explore\n",
    "6. create a retriever pipeline\n",
    "7. check the retriever time(which one is fastet)\n",
    "8. print the accuray score of every similarity search\n",
    "9. perform the reranking either using BM25 or MMR ## i have not discuss then you need to explore\n",
    "10. then write a prompt template\n",
    "11. generte a oputput through llm\n",
    "12. render that output over the DOCx ## i have not discuss then you need to explore\n",
    "as a additional tip: you can follow rag playlist from my youtube"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
